# Rationality

- Aim to get an accurate picture of reality, even when that's unpleasant. Be self-aware about what you know and what you don't know. Aim to stay close to the [humility sweet spot](https://twitter.com/waitbutwhy/status/137655374551809638).
- For each subject you think you know, ask the following questions:
  - How could I be wrong about this? [In general, be less sure about what you know than intuition implies](https://www.lesswrong.com/tag/epistemic-modesty).
  - What evidence would convince me I'm wrong?
- Be [specific](https://www.lesswrong.com/posts/XosKB3mkvmXMZ3fBQ/specificity-your-brain-s-superpower). Ask yourself the question, "What's an example of that?" Or more bluntly, "Can I be more specific?"
- Stress test your ideas/assumptions/beliefs with experiments and facts as many times as possible.
  - Anything you know or do could be wrong. You get less dumb by saying things and getting feedback. [We all have crony beliefs](https://meltingasphalt.com/crony-beliefs/). From time to time, do a self-audit and figure out which ideas you've come to hold sacred and remind yourself that they're just ideas.
  - A great way to do that is to [bet on amything](https://www.lesswrong.com/posts/ybYBCK9D7MZCcdArB/how-to-measure-anything) where you can or will find out the answer. Even if you're only testing yourself against one other person, it's a way of calibrating yourself to avoid both overconfidence and underconfidence, which will serve you in good stead emotionally when you try to do inadequacy reasoning. It'll also force you to do falsifiable predictions.
- You can try things to find out which ideas are right or wrong. It requires asking "What else would be true if this thing were true?" or "What would be different depending on whether X versus Y were true?".
- Knowledge decays. Things you learned in the past might not be true nowadays (_status of Pluto as a planet, dinosaurs with feathers, number of people living, ..._). [Facts decay over time until they are no longer facts or perhaps no longer complete](https://fs.blog/2018/03/half-life/).
- Avoiding stupidity is easier than seeking brilliance. Think backward so that you can avoid failures.
- Research before judging! We do not know what we don't know. Gather as much context as you can before making any final statement.
  - [Absolute truth is relative and everyone is doing the best they can](https://letterstoanewdeveloper.com/2019/08/12/there-are-no-adults-in-the-room/). These are opportunities for you to help and learn more about the world.
- Think in distributions instead of [magic answers](http://cassandraxia.com/cogbiases). The world is [analog and not digital](https://waitbutwhy.com/2019/12/political-disney-world.html), continuous and not discrete. Nuance is everywhere.
  - Real people are complex and flawed, [full of faults and biases](https://upload.wikimedia.org/wikipedia/commons/6/65/Cognitive_bias_codex_en.svg). Each turn of events is mired in potential positives and potential negatives, which is a mess to sort out.
  - Digitizing an analog view will result in some loss of information. In that world, everything is good or bad, everyone is smart or ignorant, ones and zeros. Mistrust simple comparisons.
- Everyone belongs to a tribe and underestimates how influential that tribe is on their thinking. Tribes reduce the ability to challenge ideas or diversify your views because no one wants to lose support of the tribe. Tribes are as self-interested as people, encouraging ideas and narratives that promote their survival. But they're exponentially more influential than any single person. So tribes are very effective at promoting views that aren't analytical or rational, and people loyal to their tribes are very poor at realizing it.
- You need a view of both the micro and the macro, the forest and the trees — and how both perspectives slot together.
- Local Validity: Some argument steps are allowed steps and some argument steps aren't ([Non-Central Fallacy](https://www.lesswrong.com/posts/yCWPkLi8wJvewPbEp/the-noncentral-fallacy-the-worst-argument-in-the-world)), independently of whether they arrive at an answer you agree with.
- People can fool you by saying they saw things that they didn't see, telling you some things they know but not others or by using flawed steps when drawing conclusions. When you try to make an argument come out with a particular answer, you can fool yourself in the same way.
- Assume good faith. Trust the other person to be believing things that make sense to them, which you'd have ended up believing if you were exposed to the same stimuli, and that they are generally trying to find the the truth.
- [Notice](https://agentyduck.blogspot.com/2014/12/how-to-train-noticing.html) your internal state (cognitive and emotional).
- When you see something odd or something that doesn't fit with what you'd ordinarily expect, notice and promote it to conscious.
- [Notice when your mind is flinching away from a thought and flag that area as requiring more deliberate exploration](https://www.lesswrong.com/posts/ttGbpJQ8shBi8hDhh/checklist-of-rationality-habits).
- Notice when you are in a failure mode, and step out. For example:
  - [Motivated Reasoning or Soldier Mindset](https://youtu.be/w4RLfVxTGH4?list=WL):
    - You are fighting to make sure an argument wins.
    - You are fighting to make another argument lose.
  - You are incentivized to believe something, or not to notice something, because of social or financial rewards.
  - You're incentivized not to notice something or think it's important because it'd be physically inconvenient/annoying.
  - You are [offended/angered/defensive/agitated](https://www.lesswrong.com/posts/yCWPkLi8wJvewPbEp/the-noncentral-fallacy-the-worst-argument-in-the-world).
  - You are afraid you'll lose something important if you lose a belief.
  - You are arguing about definitions of words instead of ideas.
  - You are confused or surprised. Treat this as a red flag that something about your models is wrong.
- Notice if someone else seems to be in one of the above failure modes.
- Tactfully disagree in a way that arouses curiosity rather than defensiveness.
- [Be prejudiced in favor of tolerating dissent](https://www.lesswrong.com/posts/ZQG9cwKbct2LtmL3p/evaporative-cooling-of-group-beliefs#fn3x57).
- Leave your colleague a line of retreat.
- Socially reward people who change their mind.
- Take into account second and third order effects.
- The real costs aren't always what is shown. Costs and values are often made of multiple parts. Beware of repeated costs—they add up!
- Do your philosophical thinking in advance ([cached thoughts](https://www.lesswrong.com/posts/2MD3NMLBPCqPfnfre/cached-thoughts)), so you can concentrate on explaining well. Above all, practice staying within the one-inferential-step bound.
  - [Think for yourself about "wise" or important or emotionally fraught topics](https://www.lessestwrong.com/posts/aSQy7yHj6nPD44RNo/how-to-seem-and-be-deep) rather than letting your brain complete the pattern. If you don't stop at the first answer, and cast out replies that seem vaguely unsatisfactory, in time your thoughts will form a coherent whole, flowing from the single source of yourself, rather than being fragmentary repetitions of other people's conclusions.
  - Sometimes inferential distances can be very far apart. You need [willingness to entertain and explore ideas before deciding that they are wrong](https://slatestarcodex.com/2020/05/12/studies-on-slack/). The other person might be on a self-consistent equilibria (someone christian, creationistm, ...) and only changing one view of the world wouldn't work. You have to convince them for all the views. [A clear argument has to lay out an inferential pathway, starting from what the audience already knows or accepts](https://www.lesswrong.com/posts/HLqWn5LASfhhArZ7w/expecting-short-inferential-distances). Same applies when working with a group!
- There's a distinction between tacit knowledge and explicit knowledge:
  - Tacit knowledge is like the knowledge that you use to ride a bicycle—it's complex, experiential, intuitive, hard to put into words.
  - Explicit knowledge is clear and concrete and transferable and (at least somewhat) objectively verifiable. How you ride a bicycle is tacit, but the fact that you can ride a bicycle is explicit. It's a binary fact that can be completely and compactly transferred through words, and that is checkable through experiment.
- An event or fact is common knowledge among a group of people if everyone knows it, everyone knows that everyone knows it, everyone knows that everyone knows that everyone knows it, and so on.
- You do not think about things the same way as everyone else.
  - You may approach something analytically while others approach it intuitively — and both styles can yield the same end results!
  - Humans think in very different styles, related to how they use their senses while thinking. For example, some people see images during a conversation for each concept, others "feel" concepts in their body, others have explicit models that they update, and many have some combination. Also, some people can't imagine in images, and others can't store faces. It's very strange that we enter adult life without a shared understanding of this.
  - Don't model the minds inside other people's brains as exactly the same as your own mind. Humans lack insight into their own minds and what is [common among everyone](https://slatestarcodex.com/2014/03/17/what-universal-human-experiences-are-you-missing-without-realizing-it/) or [unusually specific to a few](https://www.lesswrong.com/posts/baTWMegR42PAsH9qJ/generalizing-from-one-example).
  - [We're all biased to our own personal history](https://www.collaborativefund.com/blog/ideas-that-changed-my-life/). Your personal experiences make up maybe 0.00000001% of what's happened in the world but maybe 80% of how you think the world works.
- [Predictive processing](https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/) gives us more confidence in an admission that bias is possible, and a hope that there's something other than bias which we can latch onto as a guide. It helps provide a convincing framework we can use to figure out what's going on at all levels of cognition.
- All points of view have complex context, many of which are predetermined by chance of birth, biology, and environment. There's no such thing as, "I only believe (x) because of (y)." our brains like simple, binary thinking, but real life is constantly challenging that impulse.
- [Cognitive ease](https://youtu.be/cebFWOlx848) makes us more likely to believe things that are familiar to us. Cognitive strain helps us avoid the pitfall of jumping to the intuitive but wrong answer. Both ways are useful in different situations, the key is to identify where to flow or fight agains the cognitive ease.

## Making Decisions

Decision making is the process we use to identify and choose alternatives, producing a final choice, which may or may not result in an action. It's basically a problem-solving activity, and it can be more or less rational or irrational based on the decision maker's values, beliefs, and (perceived) knowledge.

- Living a good life depends on our ability to make good decisions constantly.
- The decisions you make fall into two categories:
  - Prioritizing — Which path should you take first?
  - Allocating — How much attention, time, and capital should you spend on this?
- [Separate decisions into four possibilities based on the type of decision](https://fs.blog/2018/09/decision-matrix/):
  1. Irreversible and inconsequential.
  2. Irreversible and consequential. These are the ones that you really need to focus on.
  3. Reversible and inconsequential
  4. Reversible and consequential. Perfect decisions to run experiments and gather information.
- To maximize your long-term happiness, prioritize the projects you'd most regret not having pursued by the time you're old and looking back at your life.
- Gather all the information you can. Then, schedule time to think deeply about it. Brain-dump your thoughts on the problem - what's going wrong, why is it inefficient? Try to understand it in as much detail as possible.
  - Learn from the mistakes of others. You can't live long enough to make them all yourself.
  - Remember that too much information increases confidence not accuracy. Share all the information with other stakeholders. Transparency is key for group decissions. Most decisions should probably be made with somewhere around 70% of the information you wish you had. If you wait for 90%, in most cases, you're probably being slow.
- [The fog of the future hides vital information](https://youtu.be/SVmEXdGqO-s).
- If all options are similar take the harder one in the short term (_Hard decisions easy life, easy decisions, hard life_).
- Look for win-win decisions. If someone has to lose, you're not thinking hard enough or you need to make structural/incentives/environmental changes. Avoid false dichotomies. When given two great options, choose both. When given two horrible options, choose neither. Think outside the box!
- The rule of 5. Think about what the decision looks like 5 days, 5 weeks, 5 months, 5 years, 5 decades.
- Flip your goal state with your current state, and ask if you would like to go back there. This helps you switch around any biases that might be influencing your decision-making.
- Ask what information would cause you to change your mind. If you don't have that information, find it. If you do, track is religiously. Collect feedback and be open to change outcomes.
- How un-doable is a decision? If an idea is fully un-doable, make it as quickly as you can. When a decision is something that you can't take back, then it's worth really, really understanding. Aim for preserving optionality.
- We are all susceptible to bias, almost all the time. A way to detect bias and minimize the decision impact is to [run it by a bias checklist](https://www.businessinsider.com/read-this-checklist-before-you-make-any-decisions-2011-6?IR=T).
  - Noticing biases in others is easy, noticing biases in yourself is hard.
- [There are many reasons why smart people may make a poor decision](https://nesslabs.com/decision-making); Overconfidence, Analysis paralysis, Information overload, Lack of emotional or physical resources, ...
- Decision making styles:
  - Intuitive vs. Rational. System 1 vs System 2.
  - Maximizing vs. Satisficing. Go for the optimal decision or simply try to find a solution that is good enough.
  - Well defined goal vs. blurred objective. Planning all the details or trying to be as flexible as possible.
- Anecdotes are not data. Good data is carefully measured and collected information based on a range of subject-dependent factors, including, but not limited to, controlled variables, meta-analysis, and randomization.
- Most experts aren't communicators and most communicators aren't experts. This often results in research on issues being spun with a narrative by the time it reaches the public.
- How to make smart decisions once you have the data (DECIDE framework):
  1. Define the problem. Understand the problem at hand. Look for examples, think about, come up with explanations, get data, ...
  2. Establish the criteria. List all the factors you want to consider before making a decision.
  3. Consider the alternatives. Do enough research to have a few solid alternatives. Once you understand what's going wrong, think about what behaviour/environment changes could be that would lead to better outcomes
  4. Identify the best alternative. See which alternative makes most sense based on your criteria.
  5. Develop and implement a plan of action. Act on that decision. Figure out which action changes, and what concrete things should trigger them - make it something that will actually work in the moment, and can be implemented
  6. Evaluate the solution. In order to make better decisions over time, examine the outcomes and the feedback you get. The evaluation should be made [without taking account the outcome](https://en.wikipedia.org/wiki/Outcome_bias) since it wasn't known at decission time.
- Beware of cases where the decision lies in the hands of people who would gain little personally, or lose out personally, if they did what was necessary to help someone else. They have no skin in the game and no incentives.
  - [The decision makers shouldn't have competing incentives with the decision outcome](https://www.youtube.com/watch?v=Rwxkqno1PTc).
- You have a plan. A time-traveller from the future appears and tells you your plan failed. Which part of your plan do you think is the one that fails? Fix that part.
- If you're in between two decisions, don't half-ass both of them! Do one 100%, then do the other 100%.
- People reason more wisely about other people's problems than about their own.
- When you share something, add the level of confidence you have on it.
- [Understand your personal stance on the tradeoff of compromise versus purity](https://vitalik.ca/general/2020/11/08/concave.html). Given a choice between two alternatives, often both expressed as deep principled philosophies, do you naturally gravitate toward the idea that one of the two paths should be correct and we should stick to it, or do you prefer to find a way in the middle between the two extremes?


## Problem Solving

- Problems have multiple solutions at multiple levels.
- Humans get obsessed with solutions rather than first building an obsession with a problem. Obsess around problems, not solutions.
- [Most of the time problems already have solutions](http://gordonbrander.com/pattern/culture-is-a-shared-mechanism-for-problem-solving/):
  - The first group of people that encounter a problem don't know how to solve it.
  - They figure out a way of doing it, and when they get to a solution that's good enough \(not perfect, just good enough\), that's what they settle on.
  - The next time they encounter the problem, they use the same solution.
  - That keeps happening until later people don't even think about how to do it. [It's just how things are done](https://en.wikipedia.org/wiki/Einstellung_effect).
- The best thing that can be done to a problem is to dissolve it, to redesign the entity that has it or its environment so as to eliminate the problem.
  - A problem well stated is a problem half solved.
  - Insight is best thought of as a change in problem representation. The way we frame problems makes them more or less difficult.
- [Problem solving can be understood as a search problem](https://rs.io/the-science-of-problem-solving/). You start in some state, there's a set of neighbor states you can move to, and a final state that you would like to end up in.
- Taking breaks during working on a problem solving is called incubation. Incubation enhances problem solving ability.
- To improve problem solving, one should study solved problems, attack the problem while in different moods, and try explaining the problem to others. Explaining problems is good. Often in the process of laying out a problem, a solution will present itself.
- Grossman's Law: Complex problems have simple, easy to understand wrong answers. Simple explanations are appealing even when they're wrong.
- Aim for a Minimum Viable Solution. **Start small and iterate**. Fail early and learn from it. That allows you to explore, then exploit.
- When we have a problem, our instinct is to add a new habit or purchase a fix. But sometimes, you can improve your life by taking things away ([Via Negativa](https://www.artofmanliness.com/articles/via-negativa-adding-to-your-life-by-subtracting/)). For example, the foods you avoid are more important than the foods you eat.
- Your problems will tend to either be **adaptive** or **technical**. Adaptive problems require experimentation, novel strategies, or new ways of thinking and being; they're problems containing "unknown unknowns" and are often opaque in addition to being difficult. Technical problems may be equally difficult, but their difficulty lies in execution. Technical problems are those where the path to the solution is known or knowable and does not need to be discovered.
- [There's a kind of thinking you do without trying to](http://www.paulgraham.com/top.html). This type of thinking is not merely helpful in solving hard problems, but necessary. The tricky part is, you can only control it indirectly. Try to get yourself into situations where the most urgent problems are ones you want to think about.
- If a problem has no solution, it may not be a problem, but a fact - not to be solved, but to be coped with over time.
- Sometimes you can find the solution easier if you think about how not to solve the problem ([Inversion Principle](https://www.mymentalmodels.info/mms-inversion/)).

## Asking Questions

- [Ask swart questions](http://www.catb.org/esr/faqs/smart-questions.html):
  1. Do your own research first.
  2. Include things you have tried and thought of before asking the question.
  3. Be explicit about what you want to achieve in the end and provide as much up-front information as possible to help.
  4. Respect other people's time. Follow up after you get an answer.
- [When asking for help, let the people know what the problem you are trying to solve actually is instead of simply saying your solution and the reader guessing what it is you are actually trying to do](http://xyproblem.info/).
- [Think about the question like a child](https://www.aaronkharris.com/asking-questions).

## Resources

- [LessWrong](https://www.lesswrong.com/) - A community dedicated to improving reasoning and decision-making.
- [Rationality Checklist](https://www.rationality.org/resources/rationality-checklist) - Checklist for personal use, so you can have a wish-list of rationality habits and see if you're acquiring good habits.
- [Kialo](https://www.kialo.com/) - Tool to explore debates.
- [Arguman](https://arguman.org/) - An argument analysis platform.
- [Guesstimate](https://www.getguesstimate.com/) - A spreadsheet for things
- [Metaculus](https://www.metaculus.com/) - Community dedicated to generating accurate predictions about future real-world events by aggregating the collective wisdom, insight, and intelligence of its participants.
that aren't certain.
- [Rationality skill tree](https://www.lesswrong.com/posts/wccxMtZdEvHzLRNTZ/a-practice-of-rationality-sequence?commentId=BFaNYCKd3oQqQoZpH).
- [Center For Applied Rationality Handbook](https://www.rationality.org/files/cfar-handbook.pdf)
